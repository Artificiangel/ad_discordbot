# The 'tags' feature is a versatile method to tailor the bot's behavior for your use case.
# tags may be defined in this file for global effect, as well as in character cards and imgmodel definitions.

# Notes:
# - 'trigger' key is recommended for most tags (except 'global_tag_keys' and 'tag_preset_name').
# - Multiple comma-separated trigger phrases can be used per each tag (trigger: 'a boy,a dog' can match either 'a boy' or 'a dog')
# - You may simplify triggers using this syntax: 'a {boy|dog}' --- the script will read this as 'a boy,a dog'
# - The behavior of tags listed higher may override ones listed lower. Sources are also prioritized: character > imgmodel > base_tags > global_base_tags
# - Valid tag keys are detailed at the end of this file and on GitHub

# 'global_tag_keys' apply to ALL tag definitions. Keys defined in your tags will override global tag keys.
global_tag_keys:
  search_mode: userllm          # Search method for trigger matching. 'user' = user prompt only / 'llm' = bot reply only / 'userllm' = search both for matches
  case_sensitive: false         # If your triggers are case sensitive
  text_joining: ' '               # Relevant to 'insert_text'. Method of joining the inserted text to the user's llm prompt.
  img_text_joining: ', '          # Relevant to 'positive_prompt' (and '_prefix' / '_suffix'). Method of joining the inserted text to the img prompt.
  positive_prompt_method: after   # Relevant in tags with key 'positive_prompt'. 'after' = insert value after matched text / 'before' = before text / 'replace' = replace text


# 'base_tags' are always in effect. Base tags have lower priority than tags defined anywhere else.
base_tags:
    # Use '{time}' written anywhere in your prompts which will be replaced with the current time. The tags 'offset' and 'time_format' will apply to the result.
  - time_offset: 0.0                  # 0 = today's date (system time). -0.5 shifts the current date to be 12 hours ago. (UOM = days).
    time_format: '%Y-%m-%d %H:%M:%S'  # Examples: '%Y-%m-%d' (YYYY-MM-DD), '%H:%M:%S' (HH:MM:SS), '%A, %B %d, %Y' (DayName, MonthName DD, YYYY)

# A1111 payload and textgen-webui params can be randomly modified within specified ranges, or a list of strings (ex: sampler names), or from a boolean value. Must be formatted as a dictionary.
# These examples are commented out by default - you should uncomment and experiment :D
#  - img_param_variances: {cfg_scale: [-2,4], steps: [-5,5], hr_scale: [-0.50,0.15], hr_enable: false, sampler_name: ['Euler A', 'DPM++ 2M Karras', 'DPM++ 2M']}
#  - llm_param_variances: {repetition_penalty: [-0.25,0.25], temperature_last: false}

  - trigger: 'nude,erotic'
    img_censoring: 0            # 0 = disabled / 1 = blur image / 2 = block image from being generated

  - trigger: 'draw,generate'
    search_mode: user           # Only search user's prompt
    on_prefix_only: true        # Only triggers if matched at very beginning
    image_response: true        # The LLM's reply will be used for A1111 img generation
    swap_character: Minty-SDXL  # Filename of character in /characters.
    insert_text: ''
    insert_text_method: replace
    load_history: -1            # 0 = default (all history included) / -1 = prompt excludes chat history / > 1 = llm only sees this many recent exchanges.
    save_history: false         # Whether to save this interaction to history or not.

  - trigger: 'take a photo,take {a|another} picture'
    search_mode: user
    image_response: true
    instruct: '''[SYSTEM] You have been tasked with generating an image: "{}". Describe the image in vivid detail as if you were describing it to a blind person. The description in your response will be sent to an image generation API.'''

  - trigger: 'selfie,self portrait'
    search_mode: user
    image_response: true
    instruct: '''[SYSTEM] You have been tasked with taking a selfie: "{}". Include your appearance, your current state of clothing, your surroundings and what you are doing right now.'''

  - trigger: 'calculate,define'
    on_prefix_only: true
    state: {preset: 'Divine Intellect'} # Update values for textgen-webui state parameters. Must be formatted as a dictionary.

# 'tag_presets' are not in effect by default - they will be imported anywhere you use a 'tag_preset_name' tag.
# Useful for when you want to use the same set of tags for mulitple uses (a few characters, a few imgmodels, etc).
# Example: '- tag_preset_name: SDXL Tags' would be a simple way to share tags among all your SDXL imgmodels defined in dict_imgmodels.yaml.
tag_presets:
  - tag_preset_name: SDXL Turbo Payload   # Each tag preset must be named
    tags:                                 # Tag presets must have their tag definitions nested under a 'tags' key
      - payload: {width: 896, height: 1152, cfg_scale: 2, steps: 5, sampler_name: 'DPM++ SDE Karras'} # A1111 payload can be modified using 'payload'. Must be formatted as a dictionary.
      #- img_param_variances: {cfg_scale: [-0.5,0.5], steps: [-1,1], hr_scale: [-0.1,0.1], hr_enabled: true}
  
  - tag_preset_name: SDXL Payload
    tags:
      - payload: {width: 896, height: 1152, cfg_scale: 7, steps: 25, sampler_name: 'DPM++ 2M Karras', hr_scale: 1.2}
      #- img_param_variances: {cfg_scale: [-2,3], steps: [0,10], hr_scale: [-0.1,0.1], hr_enabled: true}

  - tag_preset_name: SDXL Tags
    tags:
      - trigger: 'vertical,selfie,self {photo|portrait}'
        payload: {width: 896, height: 1152}
        
      - trigger: 'horizontal,landscape'
        payload: {width: 1152, height: 896}

      - trigger: 'plain'
        payload: {override_settings: {CLIP_stop_at_last_layers: 2}} # Nested payload dictionary settings can also be modified. Must be formatted as a dictionary.

      - trigger: '{no|without|clear|empty|transparent} {bg|background}'
        layerdiffuse: '(SDXL) Only Generate Transparent Image (Attention Injection)'  # enables 'layerdiffuse' extension while applying specified method. See tag references at bottom for list of methods.
      #  Use 'payload' tag if you need more complex triggered settings for layerdiffuse
      #  payload: {'alwayson_scripts': {'layerdiffuse': {'args': [true,'Only Generate Transparent Image (Attention Injection)',0.2,1.0,null,null,null,'Crop and Resize']}}}

      - trigger: 'grimace'
        positive_prompt: '<lora:PE_Grimace_v1.0:0.75>'

      - trigger: '{ps1|playstation} {style|art|graphics},style of {ps1|playstation}'
        positive_prompt: 'ps1 style <lora:ps1_style_SDXL_v2:1.0>'
        negative_prompt: 'blurry' # 'negative_prompt' = inserted at the end of the negative prompt (does not behave like 'positive_prompt' which is relative to the matched text)
        trumps: 'low poly' # If any other matched tag has a trigger phrase matching a 'trump' phrase, it will not be used. (*can be comma separated to trump multiple tags*)

      - trigger: 'low {poly|polygon}'
        positive_prompt: '<lora:LowpolySDXL_v1.0:1.0>'
        negative_prompt: 'blurry'

  - tag_preset_name: SD15 Tags
    tags:
      - payload: {width: 512, height: 512, cfg_scale: 10, steps: 40, sampler_name: 'DPM++ 2M Karras', hr_scale: 2, hr_enabled: true, denoise_strength: 0.5}
      #- img_param_variances: {cfg_scale: [-3,1], steps: [-10,10], hr_scale: [-0.5,0.2]}

      - positive_prompt_prefix: 'masterpiece, detailed, ' # '_prefix' makes this inserted at the beginning of the image prompt
        positive_prompt_suffix: ' <lora:more_details:0.5> <lora:epiNoiseoffset_v2Pynoise:0.5>' # '_suffix' makes this inserted at the end of the image prompt
        negative_prompt_prefix: '<kkw-Extreme-Neg:0.5>, <negative_hand-neg:0.5>, by <bad-artist:0.5>, ' # same logic as positive_prompt. Can similarly use '_suffix' (or just 'negative_prompt')

      - trigger: 'selfie,self photo'
        positive_prompt: '(taking a selfie:1.2), (arms outstretched:1.1)'

      - trigger: 'gta,gta4,grand theft auto,archer style'
        positive_prompt: 'GtaSA2004 cartoon <lora:GTA_Style:1.0>'

      - trigger: 'gigachad'
        positive_prompt: '<lora:Gigachadv1:0.8>'


# List of all available tag keys:
#
# Relevant to all tags:
#   search_mode: userllm              Search method for trigger matching. 'user' = user prompt only / 'llm' = bot reply only / 'userllm' = search both for matches
#   trigger: 'trigger,another one'    Recommended for most tags (except 'global_tag_keys' and 'tag_preset_name').
#   random: 0.5                       Chance for tag to process. 0.0 = 0% chance and 1.0 = 100% chance.
#   case_sensitive: (true/false)      If the triggers are case sensitive
#   on_prefix_only: (true/false)      If triggers must be matched at beginning of the searched text
#
# Relevant to text generation (LLM):

#   time_offset: 0.0                  0 = today's date (system time). -0.5 shifts the current date to be 12 hours ago. (UOM = days)
#   time_format: '%Y-%m-%d %H:%M:%S'  Examples: '%Y-%m-%d' (YYYY-MM-DD), '%H:%M:%S' (HH:MM:SS), '%A, %B %d, %Y' (DayName, MonthName DD, YYYY)
#   instruct: 'string with a {}'      Useful for adding text before and/or after your prompt to the LLM.
#   insert_text: ''                   Text you may want to insert relative to the matched search text.
#   insert_text_method: replace       Relevant in tags with key 'pinsert_text'. 'after' = insert value after matched text / 'before' = before text / 'replace' = replace text
#   text_joining: ' '                 Relevant to all insertion methods except "replace"
#   swap_character: 'string'          Filename of character in /characters (do not include extension). That character's name, context, and state parameters will be used in LLM payload.
#   load_history: 0                   0 = default (all history included) / -1 = prompt excludes chat history / > 1 = llm only sees this many recent exchanges.
#   save_history: (true/false)        Whether to save this interaction to history or not.
#   state: {dictionary}               Update values for textgen-webui state parameters. Must be formatted as a dictionary.
#   llm_param_variances: {dictionary} Randomization ranges for textgen-webui state parameters. Must be formatted as a dictionary.

# Relevant to img generation (A1111):
#   image_response: (true/false)      If LLM's reply should include A1111 img generation
#   img_censoring: 0                  0 = disabled / 1 = blur image / 2 = block image from being generated
#   layerdiffuse: (true/false)        enables 'layerdiffuse' extension (must also be enabled in config.py)
#   face_swap: 'string'               Face image to be used with Reactor extension. Valid options: Image in 'swap_faces' (png/jpg/txt in base64) -OR- Directory name in 'swap_faces' (Picks a random face) -OR- Face model in '{A111}\models\reactor\faces' example 'Minty.safetensors'
#   positive_prompt: 'string'         Text you may want to insert relative to the matched text in the image prompt.
#   positive_prompt_method: after     Relevant to 'positive_prompt'. 'after' = insert value after matched text / 'before' = before text / 'replace' = replace text
#   positive_prompt_prefix: 'string'  Insert text at the beginning of the image positive prompt
#   positive_prompt_suffix: 'string'  Insert text at the end of the image positive prompt
#   negative_prompt_prefix: 'string'  Insert text at the beginning of the image negative prompt
#   negative_prompt: 'string'         Insert text at the end of the image negative prompt ('_suffix' also works)
#   img_text_joining: ', '            Relevant to all insertion methods except "replace"
#   payload: {dictionary}             Replacements for A1111 payload. Must be formatted as a dictionary.
#   img_param_variances: {dictionary} Randomization ranges for A1111 payload parameters. Must be formatted as a dictionary.
#   layerdiffuse: 'string'            enables 'layerdiffuse' extension with specified method. Valid: "(SD1.5) Only Generate Transparent Image (Attention Injection)", "(SD1.5) From Foreground to Background (need batch size 2)", "(SD1.5) From Background to Foreground (need batch size 2)", "(SD1.5) Generate Everything Together (need batch size 3)", "(SDXL) Only Generate Transparent Image (Attention Injection)", "(SDXL) Only Generate Transparent Image (Conv Injection)", "(SDXL) From Foreground to Blending", "(SDXL) From Foreground and Blending to Background", "(SDXL) From Background to Blending", "(SDXL) From Background and Blending to Foreground"